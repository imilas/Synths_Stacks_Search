{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import interpolate \n",
    "from torch.autograd import Variable\n",
    "import imp\n",
    "import torchaudio\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import os, random\n",
    "import pandas as pd\n",
    "import mir_utils as miru\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import pytorch_utils\n",
    "import pytorch_models\n",
    "#reload these libraries because I change them often-ish\n",
    "imp.reload(pytorch_utils)\n",
    "imp.reload(miru)\n",
    "imp.reload(pytorch_models)\n",
    "from scipy.signal import resample\n",
    "from sklearn import preprocessing\n",
    "le_major = preprocessing.LabelEncoder()\n",
    "\n",
    "SR = 22050//2\n",
    "#functions\n",
    "spec = torchaudio.functional.spectrogram\n",
    "\n",
    "def getMeanLength(x):\n",
    "    gl=x.apply(lambda z: len(z[\"audio\"]),axis=1)\n",
    "    print(gl.mean()/SR,gl.mean(),x[\"label\"].iloc[0])\n",
    "\n",
    "audio_df = pd.read_csv(\"../csvs/audio_df.csv\")\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = audio_df[audio_df[\"maj\"]==\"drums\"]\n",
    "audio_df[\"min\"] = audio_df[\"min\"].str.replace(\"tom_high\",\"kick\")\n",
    "audio_df[\"min\"] = audio_df[\"min\"].str.replace(\"tom\",\"kick\")\n",
    "audio_df[\"min\"] = audio_df[\"min\"].str.replace(\"rim\",\"snare\")\n",
    "audio_df[\"min\"] = audio_df[\"min\"].str.replace(\"clap\",\"snare\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['hat', 'kick', 'shake', 'snare'], dtype=object),\n",
       " array(['hat', 'kick', 'hat', 'hat'], dtype=object))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_major.fit(audio_df[\"min\"])\n",
    "le_major.classes_,le_major.inverse_transform([0,1,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.3862,  3.3441, 48.9174,  2.5961], device='cuda:1',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define weights\n",
    "w = [len(audio_df)/np.sum(audio_df[\"min\"]==x) for x in le_major.classes_]\n",
    "w = torch.tensor(w).to(device)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 4.33 ms, total: 1.21 s\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#define a dataset\n",
    "class audioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,audio_df,RSR=SR,transform=None):\n",
    "        self.audio_df = audio_df\n",
    "        self.minLength = SR\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        row = self.audio_df.iloc[idx]\n",
    "        try:\n",
    "            signal,sr = librosa.load(row[\"path\"])\n",
    "        except:\n",
    "            signal = np.zeros(self.minLength)\n",
    "            sr = self.minLength\n",
    "        # resample to global SR\n",
    "        signal = librosa.resample(signal,sr,self.minLength)\n",
    "        # pad the audio length if too short\n",
    "        nz = np.max((self.minLength-signal.shape[0],0))\n",
    "        signal = np.concatenate([signal[0:self.minLength],np.zeros(nz)])\n",
    "        sound={\"signal\":signal,\"major\":row[\"maj\"],\"minor\":row[\"min\"],\"path\":row[\"path\"],\"sr\":SR}\n",
    "        return sound\n",
    "    \n",
    "data_train = audioDataset(audio_df,SR)\n",
    "train_loader = DataLoader(data_train, batch_size=32,shuffle=True, num_workers=0)\n",
    "d = next(iter(train_loader))\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 11025])\n",
      "torch.Size([5512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  normalized, onesided, return_complex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kick\n",
      "torch.Size([1, 30, 9])\n",
      "5512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FREQ_BINS=30\n",
    "TIME_STEPS=10\n",
    "RESAMPLE_SR = 8000\n",
    "#defining transformations\n",
    "\n",
    "class specTrans(object):\n",
    "    def __init__(self,num_mels=50,sr=SR,time_steps=20,amp_to_power=True):\n",
    "        self.sr = sr\n",
    "        self.amp_to_power=amp_to_power\n",
    "        self.num_mels=num_mels\n",
    "        self.ampP=torchaudio.transforms.AmplitudeToDB(stype='power',top_db=60)\n",
    "        self.melP=torchaudio.transforms.MelScale(n_mels=self.num_mels, sample_rate=sr,n_stft=None)\n",
    "        self.hop_step=time_steps-1\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        wf=sample\n",
    "        wf=wf.reshape(-1,len(wf))\n",
    "        sample_length=self.sr\n",
    "\n",
    "        num_bins=wf[0].shape[0]\n",
    "        win_length=self.sr//17\n",
    "        hop_step=self.sr//self.hop_step\n",
    "        window=torch.tensor([1]*win_length)\n",
    "        s=spec(wf, 0, window, num_bins, hop_step, win_length,2,normalized=True)\n",
    "        s=self.melP(s)\n",
    "        if self.amp_to_power:\n",
    "            s=self.ampP(s)\n",
    "        s = s - s.min()\n",
    "        s = s/s.abs().max()\n",
    "\n",
    "        freq=s\n",
    "        freq[torch.isnan(freq)]=0\n",
    "        freq=freq\n",
    "        return freq.detach()\n",
    "    \n",
    "    \n",
    "\n",
    "SCALE_FACTOR = 0.5\n",
    "i = np.random.randint(len(d[\"signal\"]))\n",
    "\n",
    "original = d[\"signal\"]\n",
    "print(original.shape)\n",
    "resampled_d = interpolate(d[\"signal\"].reshape([len(d[\"signal\"]),1,-1]),scale_factor = SCALE_FACTOR,recompute_scale_factor=False).reshape([len(d[\"signal\"]),-1])\n",
    "signal = resampled_d[i]\n",
    "label = d[\"minor\"][i]\n",
    "fig = plt.figure(figsize=(20,4))\n",
    "spec_tf = specTrans(FREQ_BINS,time_steps=TIME_STEPS,sr=SR,amp_to_power=True)\n",
    "print(signal.shape)\n",
    "transformed_sample = spec_tf(original[i].float())\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "ft=transformed_sample[0]\n",
    "sf=ft.detach().numpy()\n",
    "plt.title(\"Spectrum Features\",fontsize=20)\n",
    "librosa.display.specshow(sf,cmap='gray_r',)\n",
    "plt.xlabel(\"Time Step\",fontsize=20)\n",
    "plt.ylabel(\"Magnitude of Bin\",fontsize=20)\n",
    "\n",
    "\n",
    "print(label)\n",
    "print(transformed_sample.shape)\n",
    "print(len(signal))\n",
    "Audio(signal[0:5000],rate=SR*0.5,autoplay=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z =  torch.stack(list(map(spec_tf,d[\"signal\"].float())),0)[i]\n",
    "librosa.display.specshow(z[0].numpy(),cmap='gray_r',)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "spec_tf = specTrans(FREQ_BINS,time_steps=TIME_STEPS,amp_to_power=True)\n",
    "\n",
    "adf = audio_df.copy()\n",
    "train = adf.sample(frac=0.95,random_state=420) \n",
    "test_and_valid = adf.drop(train.index)\n",
    "test = test_and_valid.sample(frac=0.90,random_state=420) \n",
    "# valid = test_and_valid.drop(test.index)\n",
    "\n",
    "train_loader = DataLoader(audioDataset(train,SR), batch_size=128,shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(audioDataset(test,SR), batch_size=256,shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5623, 266)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Spec_DVD(nn.Module):\n",
    "    def __init__(self,embed_only=False,dropout=0.075):\n",
    "        super(Conv_Spec_DVD, self).__init__()\n",
    "        self.embed_only = embed_only\n",
    "        self.dropout = dropout\n",
    "        self.conv_1d = nn.Sequential(\n",
    "                nn.Conv1d(1,128,500, stride=2, padding=5),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(128, 128, 250, stride=2, padding=4),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(128, 256, 100, stride=2, padding=3),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(256, 256, 100, stride=2, padding=2),\n",
    "                nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(256, 128, 80, stride=1, padding=3),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(128, 128, 40, stride=1, padding=3),\n",
    "                nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU())\n",
    "        self.spectrogram_layer = nn.Sequential(\n",
    "                nn.Linear(30*9,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.Linear(64,32),\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.Linear(32,16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16,16),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dropout),\n",
    "                )\n",
    "        self.l2 = nn.Sequential(\n",
    "                nn.Linear(128,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.Linear(64,32),\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.Linear(32,16),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dropout),\n",
    "                )\n",
    "        self.l3 = nn.Sequential(\n",
    "                  nn.Linear(16+16,32),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Dropout(self.dropout),\n",
    "                  nn.Linear(32,16),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(16,4),\n",
    "                )\n",
    "\n",
    "    def forward(self, x_sig,x_spec):\n",
    "        x_sig = x_sig.float()\n",
    "        bs = x_sig.shape[0]\n",
    "        bs_spec = x_spec.shape[0]\n",
    "        x_sig = x_sig.reshape(bs,1,-1).to(device)\n",
    "        x1_1d = self.conv_1d(x_sig)\n",
    "        flat_spec = x_spec.reshape([bs_spec,-1])\n",
    "        x1_fc = self.spectrogram_layer(flat_spec)\n",
    "        x1_1d = x1_1d.reshape(bs,-1)\n",
    "        x2 = self.l2(x1_1d)\n",
    "        x_agg = torch.cat((x2,x1_fc),dim=1)\n",
    "        x_final = self.l3(x_agg)\n",
    "        return x_final\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "try:\n",
    "    del cnet\n",
    "except:\n",
    "    pass\n",
    "cnet = Conv_Spec_DVD(embed_only=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"models/1d_conv_dvd/0.542_0.1510_.checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(np.log(len(ecg_paths)/np.sum(ecg_paths).to_numpy()))).to(device)\n",
    "loss_func = nn.CrossEntropyLoss(weight = w.float() )\n",
    "lr = 0.001 # learning rate\n",
    "optimizer = torch.optim.Adam(cnet.parameters(), lr=lr)\n",
    "smallest_loss,smallest_vloss = 1,1\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0] val loss: 2.81350, loss: 1.37624\n",
      "[1, 5] val loss: 2.81861, loss: 1.37173\n",
      "[1, 10] val loss: 2.68911, loss: 1.35766\n",
      "[1, 15] val loss: 2.69621, loss: 1.32126\n",
      "[1, 20] val loss: 2.48660, loss: 1.29793\n",
      "[1, 25] val loss: 2.75829, loss: 1.17364\n",
      "[1, 30] val loss: 2.29730, loss: 1.17024\n",
      "[2, 0] val loss: 1.90972, loss: 1.03793\n",
      "[2, 5] val loss: 2.92596, loss: 1.11160\n",
      "[2, 10] val loss: 2.18394, loss: 1.05956\n",
      "[2, 15] val loss: 2.00158, loss: 0.95324\n",
      "[2, 20] val loss: 1.97463, loss: 1.06879\n",
      "[2, 25] val loss: 2.09656, loss: 0.82585\n",
      "[2, 30] val loss: 2.07094, loss: 0.77507\n",
      "[2, 35] val loss: 1.91943, loss: 0.92593\n",
      "[2, 40] val loss: 1.99271, loss: 0.86414\n",
      "[3, 0] val loss: 1.75030, loss: 0.61526\n",
      "[3, 5] val loss: 1.96307, loss: 0.87493\n",
      "[3, 10] val loss: 1.83830, loss: 0.75659\n",
      "[3, 15] val loss: 1.70240, loss: 0.82629\n",
      "[3, 20] val loss: 2.28679, loss: 0.72691\n",
      "[3, 25] val loss: 1.34982, loss: 0.74381\n",
      "[3, 30] val loss: 1.72242, loss: 0.77447\n",
      "[3, 35] val loss: 1.75981, loss: 0.79708\n",
      "[3, 40] val loss: 2.25095, loss: 0.68758\n",
      "[4, 0] val loss: 2.19791, loss: 0.71260\n",
      "[4, 5] val loss: 1.68340, loss: 0.72431\n",
      "[4, 10] val loss: 2.34904, loss: 0.72125\n",
      "[4, 15] val loss: 1.53901, loss: 0.69931\n",
      "[4, 20] val loss: 1.35498, loss: 0.59260\n",
      "[4, 25] val loss: 1.19873, loss: 0.80191\n",
      "[4, 30] val loss: 1.20489, loss: 0.61178\n",
      "[4, 35] val loss: 0.97394, loss: 0.74394\n",
      "[4, 40] val loss: 1.36434, loss: 0.69267\n",
      "[5, 0] val loss: 1.25786, loss: 0.68317\n",
      "[5, 5] val loss: 1.07605, loss: 0.51056\n",
      "[5, 10] val loss: 1.13555, loss: 0.61838\n",
      "[5, 15] val loss: 1.28761, loss: 0.60805\n",
      "[5, 20] val loss: 1.30838, loss: 0.60758\n",
      "[5, 25] val loss: 1.38562, loss: 0.63088\n",
      "[5, 30] val loss: 1.04168, loss: 0.60409\n",
      "[5, 35] val loss: 1.19035, loss: 0.70653\n",
      "[5, 40] val loss: 0.94156, loss: 0.51534\n",
      "[6, 0] val loss: 1.52930, loss: 0.63027\n",
      "[6, 5] val loss: 1.86243, loss: 0.46936\n",
      "[6, 10] val loss: 1.27656, loss: 0.51687\n",
      "[6, 15] val loss: 1.33536, loss: 0.51436\n",
      "[6, 20] val loss: 1.30754, loss: 0.82702\n",
      "[6, 25] val loss: 1.45406, loss: 0.62396\n",
      "[6, 30] val loss: 1.69533, loss: 0.53525\n",
      "[6, 35] val loss: 1.05542, loss: 0.56491\n",
      "[6, 40] val loss: 0.88718, loss: 0.72472\n",
      "[7, 0] val loss: 1.31500, loss: 0.56633\n",
      "[7, 5] val loss: 1.33527, loss: 0.61415\n",
      "[7, 10] val loss: 2.25332, loss: 0.57685\n",
      "[7, 15] val loss: 1.32508, loss: 0.62738\n",
      "[7, 20] val loss: 1.13439, loss: 0.61822\n",
      "[7, 25] val loss: 1.34124, loss: 0.64028\n",
      "[7, 30] val loss: 0.90133, loss: 0.55584\n",
      "[7, 35] val loss: 1.49059, loss: 0.46537\n",
      "[7, 40] val loss: 0.86492, loss: 0.57367\n",
      "[8, 0] val loss: 1.04336, loss: 0.57597\n",
      "[8, 5] val loss: 0.91865, loss: 0.54446\n",
      "[8, 10] val loss: 0.87959, loss: 0.57316\n",
      "[8, 15] val loss: 1.23741, loss: 0.57836\n",
      "[8, 20] val loss: 1.13000, loss: 0.58028\n",
      "[8, 25] val loss: 0.81739, loss: 0.49922\n",
      "[8, 30] val loss: 2.04022, loss: 0.44282\n",
      "[8, 35] val loss: 1.38084, loss: 0.55388\n",
      "[8, 40] val loss: 0.96943, loss: 0.53337\n",
      "[9, 0] val loss: 1.09234, loss: 0.43554\n",
      "[9, 5] val loss: 1.09090, loss: 0.42597\n",
      "[9, 10] val loss: 1.01044, loss: 0.52957\n",
      "[9, 15] val loss: 0.76241, loss: 0.46487\n",
      "[9, 20] val loss: 1.47959, loss: 0.53927\n",
      "[9, 25] val loss: 1.16760, loss: 0.53598\n",
      "[9, 30] val loss: 0.95725, loss: 0.51677\n",
      "[9, 35] val loss: 1.09025, loss: 0.43010\n",
      "[9, 40] val loss: 0.75312, loss: 0.51873\n",
      "[10, 0] val loss: 1.13224, loss: 0.52359\n",
      "[10, 5] val loss: 1.04328, loss: 0.52437\n",
      "[10, 10] val loss: 1.83697, loss: 0.44488\n",
      "[10, 15] val loss: 0.98948, loss: 0.44327\n",
      "[10, 20] val loss: 1.07618, loss: 0.52054\n",
      "[10, 25] val loss: 0.89461, loss: 0.34160\n",
      "[10, 30] val loss: 1.10945, loss: 0.44399\n",
      "[10, 35] val loss: 1.92909, loss: 0.58921\n",
      "[10, 40] val loss: 0.82914, loss: 0.46281\n",
      "[11, 0] val loss: 0.99851, loss: 0.50633\n",
      "[11, 5] val loss: 0.74816, loss: 0.47566\n",
      "[11, 10] val loss: 1.23624, loss: 0.45561\n",
      "[11, 15] val loss: 0.94347, loss: 0.48573\n",
      "[11, 20] val loss: 1.10320, loss: 0.39663\n",
      "[11, 25] val loss: 0.82331, loss: 0.59238\n",
      "[11, 30] val loss: 1.27560, loss: 0.53909\n",
      "[11, 35] val loss: 1.45747, loss: 0.68153\n",
      "[11, 40] val loss: 1.81973, loss: 0.50078\n",
      "[12, 0] val loss: 0.93864, loss: 0.51742\n",
      "[12, 5] val loss: 1.04994, loss: 0.50875\n",
      "[12, 10] val loss: 0.99532, loss: 0.52899\n",
      "[12, 15] val loss: 1.46861, loss: 0.40510\n",
      "[12, 20] val loss: 0.96515, loss: 0.33736\n",
      "[12, 25] val loss: 1.02492, loss: 0.36312\n",
      "[12, 30] val loss: 1.23163, loss: 0.43207\n",
      "[12, 35] val loss: 0.99737, loss: 0.46110\n",
      "[12, 40] val loss: 1.02450, loss: 0.52742\n",
      "[13, 0] val loss: 1.15681, loss: 0.44760\n",
      "[13, 5] val loss: 1.33182, loss: 0.59330\n",
      "[13, 10] val loss: 0.88760, loss: 0.34930\n",
      "[13, 15] val loss: 1.04206, loss: 0.72520\n",
      "[13, 20] val loss: 0.89630, loss: 0.53702\n",
      "[13, 25] val loss: 1.01458, loss: 0.49205\n",
      "[13, 30] val loss: 1.11519, loss: 0.33802\n",
      "[13, 35] val loss: 0.92844, loss: 0.39965\n",
      "[13, 40] val loss: 0.98487, loss: 0.46904\n",
      "[14, 0] val loss: 1.52820, loss: 0.47721\n",
      "[14, 5] val loss: 0.91310, loss: 0.47805\n",
      "[14, 10] val loss: 1.24094, loss: 0.45348\n",
      "[14, 15] val loss: 2.42883, loss: 0.40960\n",
      "[14, 20] val loss: 0.82220, loss: 0.32527\n",
      "[14, 25] val loss: 1.77614, loss: 0.33955\n",
      "[14, 30] val loss: 0.74469, loss: 0.70418\n",
      "[14, 35] val loss: 2.12284, loss: 0.43141\n",
      "[14, 40] val loss: 1.03319, loss: 0.36949\n",
      "[15, 0] val loss: 1.33072, loss: 0.46941\n",
      "[15, 5] val loss: 1.14816, loss: 0.41366\n",
      "[15, 10] val loss: 3.06492, loss: 0.55033\n",
      "[15, 15] val loss: 1.40800, loss: 0.53261\n",
      "[15, 20] val loss: 0.92277, loss: 0.51298\n",
      "[15, 25] val loss: 0.87493, loss: 0.64257\n",
      "[15, 30] val loss: 0.88644, loss: 0.53264\n",
      "[15, 35] val loss: 0.82585, loss: 0.43651\n",
      "[15, 40] val loss: 1.12420, loss: 0.35808\n",
      "[16, 0] val loss: 0.73679, loss: 0.40876\n",
      "[16, 5] val loss: 1.06799, loss: 0.46660\n",
      "[16, 10] val loss: 1.07048, loss: 0.41277\n",
      "[16, 15] val loss: 1.12912, loss: 0.45328\n",
      "[16, 20] val loss: 0.91260, loss: 0.62610\n",
      "[16, 25] val loss: 1.02771, loss: 0.47557\n",
      "[16, 30] val loss: 1.28094, loss: 0.41987\n",
      "[16, 35] val loss: 1.14613, loss: 0.43391\n",
      "[16, 40] val loss: 1.27399, loss: 0.50745\n",
      "[17, 0] val loss: 0.81486, loss: 0.47251\n",
      "[17, 5] val loss: 0.86946, loss: 0.40514\n",
      "[17, 10] val loss: 1.15899, loss: 0.35343\n",
      "[17, 15] val loss: 1.87433, loss: 0.60049\n",
      "[17, 20] val loss: 1.10897, loss: 0.33874\n",
      "[17, 25] val loss: 1.04615, loss: 0.37950\n",
      "[17, 30] val loss: 0.85027, loss: 0.32463\n",
      "[17, 35] val loss: 1.31486, loss: 0.30553\n",
      "[17, 40] val loss: 1.74250, loss: 0.27835\n",
      "[18, 0] val loss: 0.86267, loss: 0.56732\n",
      "[18, 5] val loss: 1.49166, loss: 0.47572\n",
      "[18, 10] val loss: 1.60590, loss: 0.38733\n",
      "[18, 15] val loss: 2.80293, loss: 0.43295\n",
      "[18, 20] val loss: 1.02702, loss: 0.35974\n",
      "[18, 25] val loss: 1.01764, loss: 0.48310\n",
      "[18, 30] val loss: 0.94544, loss: 0.39306\n",
      "[18, 35] val loss: 1.36332, loss: 0.53620\n",
      "[18, 40] val loss: 2.01891, loss: 0.38003\n",
      "[19, 0] val loss: 0.77243, loss: 0.40778\n",
      "[19, 5] val loss: 0.60257, loss: 0.45291\n",
      "[19, 10] val loss: 1.02571, loss: 0.46537\n",
      "[19, 15] val loss: 0.72916, loss: 0.40421\n",
      "[19, 20] val loss: 1.20755, loss: 0.26139\n",
      "[19, 25] val loss: 1.39202, loss: 0.50284\n",
      "[19, 30] val loss: 0.72728, loss: 0.28119\n",
      "[19, 35] val loss: 0.92136, loss: 0.33204\n",
      "[19, 40] val loss: 1.67676, loss: 0.37258\n",
      "[20, 0] val loss: 0.84422, loss: 0.26270\n",
      "[20, 5] val loss: 1.36568, loss: 0.25506\n",
      "[20, 10] val loss: 1.63536, loss: 0.23024\n",
      "[20, 15] val loss: 0.70702, loss: 0.39160\n",
      "[20, 20] val loss: 0.88065, loss: 0.33449\n",
      "[20, 25] val loss: 1.58868, loss: 0.38209\n",
      "[20, 30] val loss: 1.76033, loss: 0.20649\n",
      "[20, 35] val loss: 0.89492, loss: 0.59837\n",
      "[20, 40] val loss: 0.62514, loss: 0.43568\n",
      "[21, 0] val loss: 0.97631, loss: 0.29112\n",
      "[21, 5] val loss: 1.26024, loss: 0.32642\n",
      "[21, 10] val loss: 0.56530, loss: 0.33185\n",
      "[21, 15] val loss: 1.02075, loss: 0.33561\n",
      "[21, 20] val loss: 1.44398, loss: 0.28572\n",
      "[21, 25] val loss: 2.05960, loss: 0.43315\n",
      "[21, 30] val loss: 1.73826, loss: 0.59581\n",
      "[21, 35] val loss: 1.72166, loss: 0.36898\n",
      "[21, 40] val loss: 0.68726, loss: 0.40618\n",
      "[22, 0] val loss: 1.16092, loss: 0.35041\n",
      "[22, 5] val loss: 0.94558, loss: 0.26874\n",
      "[22, 10] val loss: 0.99437, loss: 0.52363\n",
      "[22, 15] val loss: 1.08174, loss: 0.35173\n",
      "[22, 20] val loss: 0.91954, loss: 0.31995\n",
      "[22, 25] val loss: 1.19882, loss: 0.27389\n",
      "[22, 30] val loss: 1.04015, loss: 0.49423\n",
      "[22, 35] val loss: 1.30905, loss: 0.36130\n",
      "[22, 40] val loss: 1.00640, loss: 0.44818\n",
      "[23, 0] val loss: 1.27346, loss: 0.35717\n",
      "[23, 5] val loss: 0.78708, loss: 0.48623\n",
      "[23, 10] val loss: 0.87415, loss: 0.22578\n",
      "[23, 15] val loss: 1.36647, loss: 0.23745\n",
      "[23, 20] val loss: 1.03283, loss: 0.33846\n",
      "[23, 25] val loss: 1.43501, loss: 0.44212\n",
      "[23, 30] val loss: 1.49796, loss: 0.33163\n",
      "[23, 35] val loss: 1.55636, loss: 0.24829\n",
      "[23, 40] val loss: 1.58511, loss: 0.25665\n",
      "[24, 0] val loss: 1.62100, loss: 0.47321\n",
      "[24, 5] val loss: 1.22043, loss: 0.35950\n",
      "[24, 10] val loss: 0.56962, loss: 0.25133\n",
      "[24, 15] val loss: 1.05116, loss: 0.23950\n",
      "[24, 20] val loss: 0.84667, loss: 0.18783\n",
      "[24, 25] val loss: 1.31546, loss: 0.24492\n",
      "[24, 30] val loss: 1.41728, loss: 0.25788\n",
      "[24, 35] val loss: 0.71217, loss: 0.25538\n",
      "[24, 40] val loss: 1.29087, loss: 0.33724\n",
      "[25, 0] val loss: 1.42490, loss: 0.28438\n",
      "[25, 5] val loss: 1.14746, loss: 0.58981\n",
      "[25, 10] val loss: 1.05208, loss: 0.26955\n",
      "[25, 15] val loss: 1.67130, loss: 0.24343\n",
      "[25, 20] val loss: 0.67773, loss: 0.35021\n",
      "[25, 25] val loss: 0.76885, loss: 0.23840\n",
      "[25, 30] val loss: 1.55607, loss: 0.17871\n",
      "[25, 35] val loss: 0.92796, loss: 0.31707\n",
      "[25, 40] val loss: 0.81682, loss: 0.32135\n",
      "[26, 0] val loss: 2.60529, loss: 0.22011\n",
      "[26, 5] val loss: 1.10537, loss: 0.20219\n",
      "[26, 10] val loss: 4.21977, loss: 0.22839\n",
      "[26, 15] val loss: 1.33842, loss: 0.14749\n",
      "[26, 20] val loss: 1.40689, loss: 0.18862\n",
      "[26, 25] val loss: 1.50862, loss: 0.51565\n",
      "[26, 30] val loss: 1.67728, loss: 0.19065\n",
      "[26, 35] val loss: 1.77640, loss: 0.37067\n",
      "[26, 40] val loss: 0.89509, loss: 0.29658\n",
      "[27, 0] val loss: 1.17259, loss: 0.23016\n",
      "[27, 5] val loss: 1.77296, loss: 0.23243\n",
      "[27, 10] val loss: 1.02994, loss: 0.19829\n",
      "[27, 15] val loss: 1.56109, loss: 0.18550\n",
      "[27, 20] val loss: 1.07843, loss: 0.18944\n",
      "[27, 25] val loss: 2.38698, loss: 0.30383\n",
      "[27, 30] val loss: 3.51641, loss: 0.34302\n",
      "[27, 35] val loss: 1.25239, loss: 0.50301\n",
      "[27, 40] val loss: 2.69192, loss: 0.30693\n",
      "[28, 0] val loss: 1.54097, loss: 0.32985\n",
      "[28, 5] val loss: 0.98540, loss: 0.18647\n",
      "[28, 10] val loss: 0.86731, loss: 0.20555\n",
      "[28, 15] val loss: 1.10719, loss: 0.25006\n",
      "[28, 20] val loss: 0.96867, loss: 0.27526\n",
      "[28, 25] val loss: 2.41584, loss: 0.19705\n",
      "[28, 30] val loss: 1.71474, loss: 0.24283\n",
      "[28, 35] val loss: 1.29274, loss: 0.22588\n",
      "[28, 40] val loss: 1.46798, loss: 0.20498\n",
      "[29, 0] val loss: 1.70209, loss: 0.22565\n",
      "[29, 5] val loss: 1.09725, loss: 0.18071\n",
      "[29, 10] val loss: 0.79043, loss: 0.28397\n",
      "[29, 15] val loss: 0.95972, loss: 0.20095\n",
      "[29, 20] val loss: 0.77095, loss: 0.23290\n",
      "[29, 25] val loss: 0.79651, loss: 0.21696\n",
      "[29, 30] val loss: 1.29927, loss: 0.27824\n",
      "[29, 35] val loss: 1.13077, loss: 0.22579\n",
      "[29, 40] val loss: 0.83948, loss: 0.25009\n",
      "[30, 0] val loss: 1.29175, loss: 0.14717\n",
      "[30, 5] val loss: 1.12508, loss: 0.19349\n",
      "[30, 10] val loss: 1.54479, loss: 0.29175\n",
      "[30, 15] val loss: 0.75817, loss: 0.18455\n",
      "[30, 20] val loss: 2.21125, loss: 0.29556\n",
      "[30, 25] val loss: 1.27354, loss: 0.37113\n",
      "[30, 30] val loss: 1.52523, loss: 0.24632\n",
      "[30, 35] val loss: 1.21876, loss: 0.40194\n",
      "[30, 40] val loss: 1.03489, loss: 0.28752\n",
      "[31, 0] val loss: 1.06040, loss: 0.37175\n",
      "[31, 5] val loss: 3.56318, loss: 0.36775\n",
      "[31, 10] val loss: 1.00981, loss: 0.31819\n",
      "[31, 15] val loss: 0.77593, loss: 0.26592\n",
      "[31, 20] val loss: 1.06742, loss: 0.31975\n",
      "[31, 25] val loss: 1.28048, loss: 0.32098\n",
      "[31, 30] val loss: 1.05221, loss: 0.38919\n",
      "[31, 35] val loss: 1.39748, loss: 0.15213\n",
      "[31, 40] val loss: 0.76786, loss: 0.31326\n",
      "[32, 0] val loss: 0.62723, loss: 0.28400\n",
      "[32, 5] val loss: 2.66620, loss: 0.30929\n",
      "[32, 10] val loss: 2.80263, loss: 0.34792\n",
      "[32, 15] val loss: 1.94786, loss: 0.40140\n",
      "[32, 20] val loss: 0.74514, loss: 0.25212\n",
      "[32, 25] val loss: 1.13964, loss: 0.38393\n",
      "[32, 30] val loss: 1.93162, loss: 0.24869\n",
      "[32, 35] val loss: 0.75538, loss: 0.23755\n",
      "[32, 40] val loss: 0.92639, loss: 0.22996\n",
      "[33, 0] val loss: 1.17963, loss: 0.12368\n",
      "[33, 5] val loss: 0.67242, loss: 0.25000\n",
      "[33, 10] val loss: 2.44488, loss: 0.21752\n",
      "[33, 15] val loss: 0.85765, loss: 0.44708\n",
      "[33, 20] val loss: 1.71860, loss: 0.26184\n",
      "[33, 25] val loss: 0.84606, loss: 0.23883\n",
      "[33, 30] val loss: 1.28061, loss: 0.61256\n",
      "[33, 35] val loss: 0.81139, loss: 0.26634\n",
      "[33, 40] val loss: 0.97377, loss: 0.27470\n",
      "[34, 0] val loss: 0.95567, loss: 0.30710\n",
      "[34, 5] val loss: 1.29448, loss: 0.25426\n",
      "[34, 10] val loss: 1.29918, loss: 0.12396\n",
      "[34, 15] val loss: 1.22373, loss: 0.18965\n",
      "[34, 20] val loss: 3.44810, loss: 0.17164\n",
      "[34, 25] val loss: 1.14352, loss: 0.20334\n",
      "[34, 30] val loss: 1.11318, loss: 0.15849\n",
      "[34, 35] val loss: 0.85869, loss: 0.21187\n",
      "[34, 40] val loss: 1.39564, loss: 0.18081\n",
      "[35, 0] val loss: 0.84960, loss: 0.14312\n",
      "[35, 5] val loss: 0.55900, loss: 0.12562\n",
      "[35, 10] val loss: 1.00341, loss: 0.15843\n",
      "[35, 15] val loss: 1.33368, loss: 0.23308\n",
      "[35, 20] val loss: 1.39138, loss: 0.11114\n",
      "[35, 25] val loss: 2.18072, loss: 0.23766\n",
      "[35, 30] val loss: 1.00526, loss: 0.50891\n",
      "[35, 35] val loss: 0.69430, loss: 0.33064\n",
      "[35, 40] val loss: 0.85083, loss: 0.18706\n",
      "[36, 0] val loss: 0.91601, loss: 0.28430\n",
      "[36, 5] val loss: 4.08603, loss: 0.15284\n",
      "[36, 10] val loss: 0.98797, loss: 0.19189\n",
      "[36, 15] val loss: 2.33494, loss: 0.19036\n",
      "[36, 20] val loss: 1.39141, loss: 0.17743\n",
      "[36, 25] val loss: 0.65060, loss: 0.24413\n",
      "[36, 30] val loss: 4.62916, loss: 0.15730\n",
      "[36, 35] val loss: 0.65964, loss: 0.23913\n",
      "[36, 40] val loss: 0.84366, loss: 0.21188\n",
      "[37, 0] val loss: 1.10296, loss: 0.15729\n",
      "[37, 5] val loss: 1.00090, loss: 0.24112\n",
      "[37, 10] val loss: 1.51811, loss: 0.17386\n",
      "[37, 15] val loss: 1.03335, loss: 0.18518\n",
      "[37, 20] val loss: 0.74106, loss: 0.28765\n",
      "[37, 25] val loss: 1.34714, loss: 0.19646\n",
      "[37, 30] val loss: 1.01733, loss: 0.32106\n",
      "[37, 35] val loss: 0.90200, loss: 0.27903\n",
      "[37, 40] val loss: 0.81596, loss: 0.16873\n",
      "[38, 0] val loss: 0.74304, loss: 0.31097\n",
      "[38, 5] val loss: 1.46046, loss: 0.14063\n",
      "[38, 10] val loss: 1.17562, loss: 0.20423\n",
      "[38, 15] val loss: 0.96497, loss: 0.31215\n",
      "[38, 20] val loss: 1.42152, loss: 0.09177\n",
      "[38, 25] val loss: 0.80119, loss: 0.20438\n",
      "[38, 30] val loss: 2.92992, loss: 0.13282\n",
      "[38, 35] val loss: 1.32518, loss: 0.29981\n",
      "[38, 40] val loss: 1.54307, loss: 0.18013\n",
      "[39, 0] val loss: 0.87174, loss: 0.19002\n",
      "[39, 5] val loss: 0.73786, loss: 0.27373\n",
      "[39, 10] val loss: 0.72807, loss: 0.15001\n",
      "[39, 15] val loss: 3.11806, loss: 0.09992\n",
      "[39, 20] val loss: 2.32226, loss: 0.19315\n",
      "[39, 25] val loss: 1.71924, loss: 0.16014\n",
      "[39, 30] val loss: 1.29751, loss: 0.11363\n",
      "[39, 35] val loss: 2.01182, loss: 0.20142\n",
      "[39, 40] val loss: 1.34971, loss: 0.17306\n",
      "[40, 0] val loss: 2.78075, loss: 0.13662\n",
      "[40, 5] val loss: 1.93317, loss: 0.12189\n",
      "[40, 10] val loss: 0.95723, loss: 0.12453\n",
      "[40, 15] val loss: 1.43979, loss: 0.08521\n",
      "[40, 20] val loss: 1.32253, loss: 0.43042\n",
      "[40, 25] val loss: 0.54747, loss: 0.12408\n",
      "[40, 30] val loss: 1.80857, loss: 0.19602\n",
      "[40, 35] val loss: 0.58374, loss: 0.28606\n",
      "[40, 40] val loss: 1.68663, loss: 0.09183\n"
     ]
    }
   ],
   "source": [
    "SCALE_FACTOR = 0.5\n",
    "num_windows = 5\n",
    "window_shift = 300\n",
    "smallest_loss,smallest_vloss = 1000,1000\n",
    "step = 0\n",
    "for epoch in range(40): \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        train_loss = 0\n",
    "        bs = len(data[\"signal\"]) # batch size\n",
    "        signal = interpolate(data[\"signal\"].reshape([bs,1,-1]),scale_factor = SCALE_FACTOR,recompute_scale_factor=False).reshape([bs,1,-1])\n",
    "        spectrums = torch.stack(list(map(spec_tf,data[\"signal\"].float())),0).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnet(signal,spectrums)\n",
    "        y = torch.tensor(le_major.transform(data[\"minor\"])).to(device)\n",
    "        loss = loss_func(outputs,y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if i%5==0:\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0\n",
    "                for iv,datav in enumerate(test_loader, 0):\n",
    "                    signalv = interpolate(datav[\"signal\"].reshape([len(datav[\"signal\"]),1,-1]),scale_factor = SCALE_FACTOR,recompute_scale_factor=False).reshape([len(datav[\"signal\"]),-1])\n",
    "                    spectrumsv = torch.stack(list(map(spec_tf,datav[\"signal\"].float())),0).to(device)\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    voutputs = cnet(signalv,spectrumsv )\n",
    "                    vy = torch.tensor(le_major.transform(datav[\"minor\"])).to(device)\n",
    "                    vloss = loss_func(voutputs,vy.long())\n",
    "                    val_loss += vloss\n",
    "            print('[%d, %d] val loss: %.5f, loss: %.5f'%(epoch + 1, i , val_loss,train_loss))\n",
    "    #         writer.add_scalar('Loss/Training', train_loss,)\n",
    "    #         writer.add_scalar('Loss/Validation', val_loss)\n",
    "            if val_loss < smallest_vloss:        \n",
    "                torch.save({\n",
    "                'epoch': epoch,\n",
    "                'vloss': vloss,\n",
    "                'model_state_dict': cnet.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, \"models/1d_conv_dvd/%.3f_%.4f_.checkpoint\"%(val_loss,train_loss,))\n",
    "                smallest_vloss = val_loss\n",
    "                smallest_loss = train_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
