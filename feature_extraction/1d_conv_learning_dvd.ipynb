{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import interpolate \n",
    "from torch.autograd import Variable\n",
    "import imp\n",
    "import torchaudio\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import os, random\n",
    "import pandas as pd\n",
    "import mir_utils as miru\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import pytorch_utils\n",
    "import pytorch_models\n",
    "#reload these libraries because I change them often-ish\n",
    "imp.reload(pytorch_utils)\n",
    "imp.reload(miru)\n",
    "imp.reload(pytorch_models)\n",
    "from scipy.signal import resample\n",
    "from sklearn import preprocessing\n",
    "le_major = preprocessing.LabelEncoder()\n",
    "\n",
    "SR = 22050//2\n",
    "#functions\n",
    "spec = torchaudio.functional.spectrogram\n",
    "\n",
    "def getMeanLength(x):\n",
    "    gl=x.apply(lambda z: len(z[\"audio\"]),axis=1)\n",
    "    print(gl.mean()/SR,gl.mean(),x[\"label\"].iloc[0])\n",
    "\n",
    "audio_df = pd.read_csv(\"../csvs/audio_df.csv\")\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = audio_df[audio_df[\"maj\"]==\"drums\"]\n",
    "audio_df[\"min\"] = audio_df[\"min\"].str.replace(\"tom_high\",\"kick\")\n",
    "audio_df[\"min\"] = audio_df[\"min\"].str.replace(\"tom\",\"kick\")\n",
    "audio_df[\"min\"] = audio_df[\"min\"].str.replace(\"rim\",\"snare\")\n",
    "audio_df[\"min\"] = audio_df[\"min\"].str.replace(\"clap\",\"snare\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['hat', 'kick', 'shake', 'snare'], dtype=object),\n",
       " array(['hat', 'kick', 'hat', 'hat'], dtype=object))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_major.fit(audio_df[\"min\"])\n",
    "le_major.classes_,le_major.inverse_transform([0,1,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.3862,  3.3441, 48.9174,  2.5961], device='cuda:1',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define weights\n",
    "w = [len(audio_df)/np.sum(audio_df[\"min\"]==x) for x in le_major.classes_]\n",
    "w = torch.tensor(w).to(device)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 5.65 ms, total: 1.13 s\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#define a dataset\n",
    "class audioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,audio_df,RSR=SR,transform=None):\n",
    "        self.audio_df = audio_df\n",
    "        self.minLength = SR\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        row = self.audio_df.iloc[idx]\n",
    "        try:\n",
    "            signal,sr = librosa.load(row[\"path\"])\n",
    "        except:\n",
    "            signal = np.zeros(self.minLength)\n",
    "            sr = self.minLength\n",
    "        # resample to global SR\n",
    "        signal = librosa.resample(signal,sr,self.minLength)\n",
    "        # pad the audio length if too short\n",
    "        nz = np.max((self.minLength-signal.shape[0],0))\n",
    "        signal = np.concatenate([signal[0:self.minLength],np.zeros(nz)])\n",
    "        sound={\"signal\":signal,\"major\":row[\"maj\"],\"minor\":row[\"min\"],\"path\":row[\"path\"],\"sr\":SR}\n",
    "        return sound\n",
    "    \n",
    "data_train = audioDataset(audio_df,SR)\n",
    "train_loader = DataLoader(data_train, batch_size=32,shuffle=True, num_workers=0)\n",
    "d = next(iter(train_loader))\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 11025])\n",
      "torch.Size([5512])\n",
      "hat\n",
      "torch.Size([1, 30, 9])\n",
      "5512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  normalized, onesided, return_complex)\n",
      "/home/asalimi/miniconda3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  normalized, onesided, return_complex)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEvCAYAAACKSII9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7xcVXnw8d+TkHAnQEQQNBcoeMFLqCBIuXuj3kDQFkQxitbaWvF929e+VhAUW630rbVaX1tbiFiKNwQKVSvIrYiUchMtiqLcNRAgCRAIJDlP/1h7ZBjmnDM72Sezc87v+/nszz6z95q9n5lJ5pm19lprR2YiSZLaadqwA5AkSaMzUUuS1GImakmSWsxELUlSi5moJUlqMRO1JEktZqKWJKnFTNRqjYiYHhHviojLIuKBiFgVEfdGxI0R8Y8R8fphxziWiDgoIjIiTh52LE2LiHnVaxtrOWg9xrNRdc6L1tc5pWHZaNgBSFCSNHABcCiwDPg34C5gJrA78GbgOcC/DitGAbAc+JtR9t22HuOQpgwTtdriaEqS/gFwYGYu794ZEZsBew8jMD3Jssw8edhBSFOJTd9qi32r9aLeJA2QmY9k5iXd2yJiYdX8uTAiXhMRV0bEiohYGhFfj4hd+50oIjaLiA9GxA1V+Ycj4vsRcfRowUXEKyPi/Kop/rGIuDMizouIl1f7FwGd+E7q1yTcE++hEXFpRCyPiKz2d5qXF40Sw6Wdsl3bft3cHhF7RsS3q2MujYizI+JZVbmdI+LLEbEkIh6NiEsi4kWjvd4mRMTsiPjLiPhJRKyMiGURcWHnPespu3VEfKCK6+6IeLx6r8+NiL17yr4TWFU9fFnPe31CVebl3Y/7nO+uiLil97jVc94SEa+uLsEsj4hVPeWeFxFnVMd4PCIWR8SZ/f69RcQOEfHXEXFz9W9tWfV+nB4R8+q8n5q6rFGrLe6v1rutxXOPAH4bOAe4FFgAHAkcHBH7ZubNnYIRsTVwMbAHcB1wGuUH66uAf4mI3TPzSV/uEfER4MPAw8C5wJ3AjpQfF28BLqq2A7wNuKyKo+O2nnjfSGk9+BbweWDuWrzmXnsBf1qd+wvACyjvy/Mj4jDgCuAnwBnV+Y4ALoyInTPz4QbO/yQRMZ/yw2UucDnwTWBL4LXAdyLiuMw8vespzwc+VsV/PuXyx1zg9cCrI+LVmdm5Hn0dcApwInBr9Zo6Lm8g/N+l/Hv6JuXzeVbX63oN8HVgehXnz6v9RwKviYgDM/MHVdnNgSuBecCFlMs206rX9QbgK3i5QIPITBeXoS+UxPk4MAJ8iZJI5o7znIVAVstre/YdX23/bs/2RdX2D/Rs3wT4dnX+BV3bX1mV/wWwU58Yntn190FV2ZPHiXcEOLTP/nnV/kWjPP/S8l/2Sds650zgmJ59/1RtfwD4UM++E6t9xw/4+XRiWwac3Gc5vKf8FdXrfFPP9m2AHwIrgO26tm8NzO5z3rnAYuCHPds3quK5aJR4X17tP2GU/XcBt/Rse2f1nDXAK/o8Z3b1+pcAz+nZ98LqNf1X17Y3VMc7tc+xNga2HMb/NZcNb7HpW62QmddTaqf3VOuzgdsi4v6IOCciXjfG0y/OzAt6tn2WUts5JCLmQmmKrY59TWZ+suf8Kyk10qB0XOv4o2r9x5l5d5+47xr0NXY5LzO/vRbPG8sVmXlmz7YvVuvlwCd69nVqoQtqnmcWcFKf5fBOgYh4MfBbwFcy82vdT87MpZTEvhklkXW2L8vM++mRmbcD36C0DOxYM9a19Y3MvLDP9oWU139CZv6ke0dm3khpndkzInpbhR7tPVBmPpaZDzUUryY5m77VGpn51Yg4BzgY2I9Sy96PkgQOj4gzgIWZ2Xtv1sv6HGtNRFwB7FId53ZK8/B0YLQhVDOq9XO7tu1DqRU1mVivbvBYHdf02fbLan1DZq7p2df50fHMmue5PTPnjVPmpdV6m1He5+2rdff7TETsD7yP8p4/ndLjv9tOPPGaJtJon0/nde0xyuv6jWr9XOCnlKb/XwEnRMRelKb071E+j5HmwtVkZ6JWq2TmKuA71dIZtnUkpbZyLOU69Lk9T7tnlMMtrtazqvXsar1XtYxmi66/twaWZuZTakXrYPH4RWp7Sgc8YPVo+zJzdUTAEz9OmtR5n19VLaP59fscEW8CvkypfV5IudSwgtJ8fgiwP6W5eH0Y7fPpvK53j/P8LaC0EkTEPpQWhNdR+iUALImIvwP+PDNX9z+E9AQTtVqtqgl+NSJeAJxA+dLuTdTbP+WJxQ7VennP+lOZ+b8HDGEZMDsiNm0wWfe2CHR0almj/b/cuqHzT7TO+/yHmfm5AZ9zCrASeHF2df4DqHqu718zhvHey1nV+foZ7fPpvK7dM/OmQYLIzDuAd0TENOB5lH+/76Ukb4CPDHIcTW1eo9aGonM9L/rsO7B3Q1UT3696eH21vpryBV7nS/+q6pyHjleQ0gkJSvP62lharZ/VuyMitmLtesQPw1XVus77vAvwoz5JejrlenevTiIe7b0e6718Dk9uNRnU2rwuADJzJDN/lJl/yxOtDIeP9Rypw0StVoiIoyPiFVXNo3ffDsC7qof9ht8cEhGv7dn2XsqX/yVVhyQy817gTEqHnxOrJNB7rl2qoUUdn6nW/y8idupTvntbpzPUnD4xjqvqXPQT4Lci4nld55gO/DWw6docd33LzKuA7wO/ExFv61cmIl4UEU/r2nQ78Ozqs+6UCeCjwLP7nGOEkoxHe69vogyne0P3eaJMnPPpeq/o1/4JeBD4aETs2bszyhS4B3U9fn5EPL3PcTotQI+sZRyaYmz6VlvsTRlStbjqBHZrtX0+8BpKkjqPMoa11/nAOVVHtFsoPZl/mzIs6Q96yr4X2JWSAN5aneseyrjo51KuXR/dOX9mficiPkZpdv9xRHTGUW9PqbFfRekNDHAzpZPWUdUkGbdTmlG/1PmxMIBTKQnhexHxNUrz7MGUa8k/ACZ0kpIGHQV8F1gUEe+ntGYso3ReW0BpBt4LuK8q/ylKT/0bIuJsyvX1/SmtCBdQxl/3+i7wxog4j9Jqshq4NDOvyMzHIuIzwAerY55DeQ9fRflcRuvXMKrMXFJdSz8buDrKPOM3UT7jOZRx9VvyRG39UODjEXElpXPZEkoN/zBKi8CpdWPQFDXs8WEuLpkJ5QvsDymdxW6m1Fwep/Sa/SZlWNW0nucspHxJLqR8kX+f0gFpGeXLdLdRzjWTkrCvpFx3fAy4g/LF/376j+d9NaXn9wNV+TurWA/pKbdXdZzllC/jBA7qjXec9+I44L+r8ywG/p7SkelSRh9HfXKf48xj7HHZSUlsg3w+nWPdVuMz3YryA+c6Su32EUonsQsoLSSb9ZR/B+XHyCOUBP4NyjzvH6vOvV9P+R2As4B7KZcdnjRumtJi+KHqnI9Xn/HHKT/6xhpH/ZZxXtfOwOcoPwpXVp/1TyjD4V7fVW53yg+QayhJeiVlgpOvAvsM+/+cy4azROZo/SakdouIhcDpwNszc9Fwo5GkieE1akmSWsxELUlSi5moJUlqMa9RS5LUYkMbnhU999XdUO244/q6T8DEmj179viFNhAzZ/ZOES1J7Xbttdfel5nb9dvnOOp19J73vGfYITTi2GOPHXYIjZkzZ63mG5GkoYmIUeda8Bq1JEktZqKWJKnFTNSSJLWYiVqSpBYzUUuS1GImakmSWsxELUlSiw1zwpNJMTHF5ptvPuwQGhERww5BktSHNWpJklrMRC1JUouZqCVJajETtSRJLWailiSpxUzUkiS1mIlakqQWG9o46sxk9erVwzp9Y1auXDnsEBqxYsWKYYcgSerDGrUkSS1mopYkqcVM1JIktZiJWpKkFjNRS5LUYiZqSZJazEQtSVKLDW0c9YwZM3j6058+rNM3ZpNNNhl2CI3Yaquthh2CJKkPa9SSJLWYiVqSpBYzUUuS1GImakmSWsxELUlSi5moJUlqMRO1JEktZqKWJKnFhjbhycjICCtWrBjW6Rszbdrk+K3z6KOPDjsESVIfkyPLSJI0SZmoJUlqMRO1JEktZqKWJKnFTNSSJLWYiVqSpBarNTwrInYFjgdeAmwDTO9TLDNzlwZikyRpyhs4UUfES4GLgE2B1cA91fopRQc9ZmYOWrS1Jsv44+nT+/3mkiQNW50a9ceBjYHfB07LzH5JWpIkNahOot4L+Hpm/sNEBSNJkp6sTmeyx4E7JioQSZL0VHUS9ZXAHhMViCRJeqo6ifrPgH0j4q0TFYwkSXqyOteoDwMuBhZFxDuBa4FlfcplZp7SRHCSJE11dRL1yV1/718t/SRgopYkqQF1EvXBTZ54+vTpbLPNNk0ecihmzZo17BAaMXv27GGHIEnqY+BEnZmXTWQgkiTpqZzrW5KkFjNRS5LUYqM2fUfECDACPC8zf1o9HmRy7szMWjf7kCRJ/Y2VUC+nJOZHeh5LkqT1ZNREnZkHjfVYkiRNPK9RS5LUYkO7ljxt2jQ222yzYZ2+MfPnzx92CI1YuXLlsENozJZbbjnsECSpMePWqKM4ICKOjIidu7YviIhvRcT9EbE0Ir4REbtObLiSJE0tY9aoI2JT4Fs8MV3oSET8EXApcBnQXXU5nHLTjgWZuXgCYpUkacoZr0b9fuAA4C7gHOCXwCeBEyj3p34X8ELgwGr/04H/M1HBSpI01Yx3jfqNwK+AF2TmgxExC/hv4GjgLZl5VqdgRHyv2nco8McTFK8kSVPKeDXqXYHzM/NBgMxcDlxQ7buou2BmjlBugzmv4RglSZqyxkvUWwC915vvAcjMJX3K3wts0kBckiSJwcZRj4zzWJIkTZChjaPOTFatWjWs0zdmyZJ+DQsbnsnwWUjSZDRIoj48IuZ1PV4AEBGn9Sm7RwMxSZKkyiCJekG19Fo4Snlv3CFJUkPGS9RvXy9RSJKkvsZM1Jn5xfUViCRJeirvniVJUouZqCVJajETtSRJLWailiSpxYY24cnIyAgrVqwY1ukbM23a5Pits3r16mGHIEnqY3JkGUmSJqlRE3VE/HVEvLLr8ZyI2Gr9hCVJkmDsGvX7gX26Ht8KHD+x4UiSpG5jJeqHgc26Hke1SJKk9WSszmS3AEdExDnAr6ptW0fEnPEOmpl3NBGcJElT3ViJ+lTgn4Eru7Ydz/jN3znOcSVJ0oBGTaiZeVZE3Aq8BtiJcresG4Eb1k9okiRpvJtyXAVcBRARC4FzMvOjTZx4zZo1PPTQQ00caqhWrlw57BAacf/99w87hMbMmTPu1RlJ2mDUaaJ+O3D9RAUiSZKeauBE7S0vJUla/2rPTBYRR0XERRFxf0SsjogHIuLCiDhqIgKUJGkqG7hGHREBnAG8mTKeeg2wBHga8DLgkIh4XWYeMxGBSpI0FdWpUb8bOAa4Dng5sElmPgPYpHp8LXBURPx+41FKkjRF1UnU7wBuAw7IzIszcw1AZq7JzIuBA6v9xzUdpCRJU1WdRP08yvCsR/vtrLafCzy3icAkSVK94VnJ+HN9DzwX+LRp09hss83GL9hymTnsEBqx5ZZbDjsESVIfdWrUP6bM/b1pv53V9sOBm5oITJIk1UvUpwFzgMsj4mURsRFAREyPiIOBS4C5VTlJktSAOk3ffw/sDxwNfAcYiYgHgG0pCT+Ar2bm5xuPUpKkKWrgGnUWx1CGaF0MLKck6eXV42My00lPJElqUO3bUWbmWcBZExCLJEnqUXsKUUmStP6YqCVJarHaTd9NiQimTdvwfydMhrHgADNmzBh2CJKkPjb8TClJ0iRmopYkqcVM1JIktZiJWpKkFlurzmQR8RzKXbK2yMwvNRuSJEnqqFWjjogFEXEN8N/A14FFXfsOjIhHIuJ1zYYoSdLUNXCijojdgEuBZwOfBr7VU+Ry4AHgjU0FJ0nSVFen6fskYCawZ2beFBEnAb/d2ZmZGRHfB/Ya9ICTYRz1ZLkfdcTAtxKXJK1HdTLly4BvZOZY95u+E9hx3UKSJEkddRL1NsBd45QJSq1bkiQ1oE6ivgf4jXHK7E6pVUuSpAbUSdQXA6+LiGf32xkRe1Gax/+9icAkSVK9RP1xYDVweUS8h+padETsXj0+H3gI+KvGo5QkaYoauNd3Zt4cEUcCZwGfrTYHcGO1XgYckZl3NB6lJElTVK2ZyTLz2xExH3gbsA8wG1gOXAWcnpkPNB+iJElTV+0pRDNzGWXCk0+vy4kzk1WrVq3LIVph1qxZww6hEY6jlqR22vBnHJEkaRIbtUYdEQes7UEz8/K1fa4kSXrCWE3flwJrOz/m9LV8niRJ6jJWov4oT03UewOHAj8HrgAWAzsA+wG7UG7UcXXzYUqSNDWNmqgz8+TuxxGxD/BB4Hjg7zJzpGvfNOCPgE9QErwkSWpAnc5kpwAXZeZnupM0QGaOZOanKbOXmaglSWpInUT9EuCGccrcQBlfLUmSGlAnUQflOvRYxrtphyRJqqHOhCdXAkdGxGsz84LenRHxeuAI4MJBDhYRbLRR7flWWmfZsmXDDqERG2+88bBDkCT1USdTfgi4HDgvIi6r/r4H2B44EDgAeLQqJ0mSGlDnphzXRsQrgNOAg6olKU3iADcDx2Xm9Q3HKEnSlFX3phxXAs+JiH2B3wRmUW7KcV21T5IkNWitLhJXSdnELEnSBPOmHJIktdjANeqI+PCARTMzT1nLeCRJUpc6Td8nj7GvMyd4VH+bqCVJakCdRH3wKNu3BvYC3gf8G/D5QQ42c+ZM5s6dW+P07bTtttsOO4RGzJ49e9ghSJL6qDM867Ixdp8XEV+h3Dnry+sclSRJAhrsTJaZPwTOA/6sqWNKkjTVNd3r+w7g+Q0fU5KkKavpRL03ZRpRSZLUgDrDs+aMcYxnAe8C9gO+2kBckiSJer2+b+OJYVj9BPAz4E/WJSBJkvSEOon6DPon6hFgKaXH93mZ+VgTgUmSpHrDsxY2eeLVq1fzwAMPNHnIoZgxY8awQ2jEfffdN+wQGrP99tsPOwRJaszAnckiYk5EbDVOmS3HuJYtSZJqqtPr+1bg/eOUeV9VTpIkNaBOoo4Ji0KSJPXV9DjqHYAVDR9TkqQpa8zOZBFxbM+mBX22AUwH5gBvAX7YUGySJE154/X6XsQTQ7ISOKxaenWaxR8BPtJIZJIkadxE/fZqHcBpwLmUG2/0WgPcD3w/M5c1F54kSVPbmIk6M7/Y+Tsi3gacm5lnNHHiVatWcffddzdxqKF67LHJMb/LkiVLhh1CYxxHLWkyqTPhycETGYgkSXqqpnt9S5KkBo1ao46IX1A6kL08M2+tHg8iM3OXRqKTJGmKG6vpexpPvglH7+PRODGKJEkNGTVRZ+a8sR5LkqSJ5zVqSZJazEQtSVKLDTw8qyMi9gReAmxDmTq0V2bmKQMch4033rju6Vtn8eLFww6hETvttNOwQ5Ak9TFwoq7uRf0N4GDG7jCWwLiJWpIkja9OjfpU4BDgP4DTgTuB1RMRlCRJKuok6sOA64CDM3NkguKRJEld6nQmmwVcYpKWJGn9qZOofwZ4twNJktajOon674DXRYTdgyVJWk/qXKP+FqUz2fci4iPAtUDfe09n5h0NxCZJ0pRXJ1HfRhl6FcA/jlEuBznumjVrWL58eY3Tt9NkuY/ztGmTZ+6bRx99dNghNGLTTTcddgiSWqBOoj6DwW7KIUmSGjJwos7MhRMYhyRJ6mPytHdKkjQJmaglSWqxOnN9nzZAsRHgQeDHwPmZOTnuWCFJ0pDU6Uy2kCc6k/W7KUf2bP9sRJyQmaeuZWySJE15dZq+dwHOA+4HTgAOAp5brU+stp8D7A28G7gH+EREHNZcuJIkTS11atSHA/sDCzLz7q7tNwOXR8QZwPXAf2Tm30TEvwM3Ae+lJHhJklRTnUT9e8DXepL0r2XmnRHxtarc32TmHRFxAfCKfuWnTZs2KSZ0mD9//rBDaMSaNWuGHUJjJsO/K0nqqNP0PQ8YbyqxZUB35roN2KJeSJIkqaNOor6PUWrHXV5JuVbdsTXjJ3dJkjSKOon6bOA3I+KfI2JO946ImBMRZwILgK937Xox5faYkiRpLdS5Rv1hSmeyNwO/GxF3U3p2bw/sBEwHbqjKERHPAFYBX2oyYEmSppI6c30/GBH7Ah8A3gbsDHRq1r+g3LTjk5m5sir/K2DfZsOVJGlqqVOjJjMfA04BTomILYGtgAcz86GJCE6SpKmuVqLuViVnE7QkSRNorRP1upo5cyY77bTTsE7fmMkyZne77bYbdgiSpD5qJeqI2Bz4A+BVlA5kG/cplpm5SwOxSZI05dW5e9bWwBXA8yh3yNqKMkZ6JtCpVv6S0tNbkiQ1oM446hMoSfo4YJtq26coM4/tC1wH/Jxyow5JktSAOon69cDlmXl6ZnZud0kWVwGvBp4DfKjhGCVJmrLqJOpnAdd2PR6h6xp1Zt4LfAs4qpnQJElSnUT9CCU5dywHdugpcw+lk5kkSWpAnUR9J6VW3XETcEBEdB9jP2BxE4FJkqR6w7MuA34nIqK6Rv0V4G+Bb0bE+cBBwD7A/x/kYGvWrOHBBx+sGW77RMSwQ5AkTWJ1EvUXKUOxnkmpXX8eOAQ4nHJ7S4DvUXqHS5KkBtS5Kcd1wHu6Hq8GjoiIFwO/AdwG/FdmjvQ/giRJqmudpxDNzGt5cm9wSZLUkDqdySRJ0no2Zo06Io5dm4Nm5hlrF44kSeo2XtP3IiDHKdMtqvImakmSGjDINerVwPnAjyc4FkmS1GO8RH0ZcCDwBmB74AvAVzNz5bqeODNZvXr1uh5m6B566KFhh9CIlSvX+SOVJE2AMTuTZebBwG7AXwG7AqcDv4qIz0TEC9dDfJIkTWnj9vrOzFsy808pE538DvCflPHU10fE1RFxXERsPsFxSpI0JQ08PCszV2fm2Zl5KLAL8BfAM4B/AH4ZES+doBglSZqy1mocdWbenpknAu8G7ga2ALZrMjBJkrQWM5NFxI7AO6plLrAS+GfgumZDkyRJAyXq6laWrwXeCRxaPe+HwPHAlzJz+YRFKEnSFDbezGTzgeOAt1OuR6+g3EXrC5l59cSHJ0nS1DZejfqWan0NcBJwVmauaOLEk2Uc9bbbbjvsEBrx8MMPDzuExixdunTYITRim222GXYIklpgvEQdwCpKbfrDwIcjYrxjZmbObSA2SZKmvEGuUc+gjKGWJEnr2ZiJOjO9DaYkSUNkIpYkqcVM1JIktZiJWpKkFjNRS5LUYiZqSZJarPZc302ZPn06W2211bBO35jFixcPO4RGLFiwYNghNMaJQiRNJtaoJUlqMRO1JEktZqKWJKnFTNSSJLWYiVqSpBYzUUuS1GImakmSWsxx1OtoZGRk2CE0Yttttx12CJKkPqxRS5LUYiZqSZJazEQtSVKLmaglSWoxE7UkSS1mopYkqcVM1JIktdjQxlEDZOYwT9+IyTKO+vbbbx92CI3Zbbfdhh2CJDXGGrUkSS1mopYkqcVM1JIktZiJWpKkFjNRS5LUYiZqSZJazEQtSVKLDW0c9cyZM5k/f/6wTt+YzTfffNghNGKHHXYYdgiSpD6sUUuS1GImakmSWsxELUlSi5moJUlqMRO1JEktZqKWJKnFTNSSJLVYDOue0BGxBJg8N0GWJGntzc3M7frtGFqiliRJ47PpW5KkFjNRS5LUYiZqSZJazEQtrUcRcWlE2DFE0sBM1NJaiIisuSwcdsxrKyJeERHnRMQvI+LxiFgaET+NiK9FxPsiIrrKzqte76IhhixNKkO7zaW0gftIn23vB2YBnwaW9ey7oVofC2w2gXE1KiL+DPhzYDXwbeBmYA2wC3Ag8Ebgc9V+SRPA4VlSQyLiNmAuMD8zbxtuNOsuIuYCPwdWAPtl5g979k8DXgF8J6svkoiYB9wKfDEzF67PeKXJyqZvaT3qd406Ig6qmotPjog9I+LbEbG8amI+OyKeVZXbOSK+HBFLIuLRiLgkIl40ynk2i4gPRsQNEbEiIh6OiO9HxNE1wt0bmA5c0pukATJzJDP/vStJn0xJ0gBvG6vpPyJeFRHfjIj7IuKxiPh5RJwaEVv3eS23VcusiPhsRNwdESsj4qbepndpMrLpW2qPvYA/BS4DvgC8ADgCeH5EHAZcAfwEOINScz8CuDAids7MhzsHqZLdxcAewHXAaZQf5a8C/iUids/MEwaI5/5qvXNETM/MNeOUvxTYGjge+AFwbte+TtM/EXEScDLwAHABcC/wQuBPgFdHxEsz88GeY88ELqqO/+Xq8ZGUywzPBv5wgNcjbZgy08XFpYEFuA1IYN4YZS4t/+2etO2g6nkJHNOz75+q7Q8AH+rZd2K17/ie7Yuq7R/o2b4J5TrzCLBggNezeddruhx4B7A7MH2M58yryi8aZf/B1f4rga179i2s9n1qlPf1CmDjru3bUprmEzhg2J+/i8tELTZ9S+1xRWae2bPti9V6OfCJnn1nVOsFnQ0RMRt4C3BNZn6yu3BmrqTU2AN483jBZOYK4PWU2vD+lB8NPwIeiojLIuIPImLjQV5Yl/dV63dl5pM63GXmoupcx4zy3A9m5mNd5R8ATqkevr1mHNIGw6ZvqT2u6bPtl9X6hnxq0/Pd1fqZXdv2olxXzuqaca8Z1fq5gwSUmTcCe0TEnpTa8G8CLwUOqJbfi4iDM3PpIMernrsKeFNEvKnP/pnAdhExOzPv79q+mlIL73Vptd5jwPNLGxwTtdQey/tsWz3avsxcXfWjmtG1eXa13qtaRrNFncAy8xq6fkhExEsotf0XASdRhqYNYjble+ekccptwRPXyAHu6/NDBWBxtZ414PmlDY5N39Lk0knon8rMGGM5eF1OkplXA++tHh5SM76l48QWmdl7C9ynRcT0Psfboeu40qRkopYml6spncX2Xw/neqhadw+P6tR6+yVVgKuAbSJi95rn2gjYt8/2g6r19TWPJ20wTNTSJJKZ9wJnAntGxIn9aqERsUtEzB/vWBHxkohYGBGb9tk3g9IxDUqP8I6llF7Yc0Y57Keq9RciYsc+x908IvYZ5bkf7+68FhHbAp1hZqeP/kqkDZvXqKXJ573ArsBHgbdGxEd4WdoAAAElSURBVBXAPcCOlE5kewFH88TkJKPZkZIAP1sd4yZgJfAM4FBKs/Mt1XkAyMyHI+I/gf0j4kzgp5Ra9r9m5o2Z+d2I+L/Ax4GfRcQ3qzi2oIwNP5AyDOvQnlh+BWwM/Cgi/pVyXf6NVSyfy8zLkSYpE7U0yWTmgxFxIPB7lGFYR1LGUN8D/Az4X8CFAxzqu9XzXwm8GNiTMuHIg5SJVz4NfDa7JlupvJVScz6U8oMggLuAG6v4/jIivkcZqrUfcBjlGvPdwD8A/9InlseBlwN/ARwFPA34BWXI2mcGeC3SBsu5viW1WjWHOpk5b7iRSMPhNWpJklrMRC1JUouZqCVJajGvUUuS1GLWqCVJajETtSRJLWailiSpxUzUkiS1mIlakqQW+x/k9GvIZ3nKjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FREQ_BINS=30\n",
    "TIME_STEPS=10\n",
    "RESAMPLE_SR = 8000\n",
    "#defining transformations\n",
    "\n",
    "class specTrans(object):\n",
    "    def __init__(self,num_mels=50,sr=SR,time_steps=20,amp_to_power=True):\n",
    "        self.sr = sr\n",
    "        self.amp_to_power=amp_to_power\n",
    "        self.num_mels=num_mels\n",
    "        self.ampP=torchaudio.transforms.AmplitudeToDB(stype='power',top_db=60)\n",
    "        self.melP=torchaudio.transforms.MelScale(n_mels=self.num_mels, sample_rate=sr,n_stft=None)\n",
    "        self.hop_step=time_steps-1\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        wf=sample\n",
    "        wf=wf.reshape(-1,len(wf))\n",
    "        sample_length=self.sr\n",
    "\n",
    "        num_bins=wf[0].shape[0]\n",
    "        win_length=self.sr//17\n",
    "        hop_step=self.sr//self.hop_step\n",
    "        window=torch.tensor([1]*win_length)\n",
    "        s=spec(wf, 0, window, num_bins, hop_step, win_length,2,normalized=True)\n",
    "        s=self.melP(s)\n",
    "        if self.amp_to_power:\n",
    "            s=self.ampP(s)\n",
    "        s = s - s.min()\n",
    "        s = s/s.abs().max()\n",
    "\n",
    "        freq=s\n",
    "        freq[torch.isnan(freq)]=0\n",
    "        freq=freq\n",
    "        return freq.detach()\n",
    "    \n",
    "    \n",
    "\n",
    "SCALE_FACTOR = 0.5\n",
    "i = np.random.randint(len(d[\"signal\"]))\n",
    "\n",
    "original = d[\"signal\"]\n",
    "print(original.shape)\n",
    "resampled_d = interpolate(d[\"signal\"].reshape([len(d[\"signal\"]),1,-1]),scale_factor = SCALE_FACTOR,recompute_scale_factor=False).reshape([len(d[\"signal\"]),-1])\n",
    "signal = resampled_d[i]\n",
    "label = d[\"minor\"][i]\n",
    "fig = plt.figure(figsize=(20,4))\n",
    "spec_tf = specTrans(FREQ_BINS,time_steps=TIME_STEPS,sr=SR,amp_to_power=True)\n",
    "print(signal.shape)\n",
    "transformed_sample = spec_tf(original[i].float())\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "ft=transformed_sample[0]\n",
    "sf=ft.detach().numpy()\n",
    "plt.title(\"Spectrum Features\",fontsize=20)\n",
    "librosa.display.specshow(sf,cmap='gray_r',)\n",
    "plt.xlabel(\"Time Step\",fontsize=20)\n",
    "plt.ylabel(\"Magnitude of Bin\",fontsize=20)\n",
    "\n",
    "\n",
    "print(label)\n",
    "print(transformed_sample.shape)\n",
    "print(len(signal))\n",
    "Audio(signal[0:5000],rate=SR*0.5,autoplay=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z =  torch.stack(list(map(spec_tf,d[\"signal\"].float())),0)[i]\n",
    "librosa.display.specshow(z[0].numpy(),cmap='gray_r',)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "spec_tf = specTrans(FREQ_BINS,time_steps=TIME_STEPS,amp_to_power=True)\n",
    "\n",
    "adf = audio_df.copy()\n",
    "train = adf.sample(frac=0.95,random_state=420) \n",
    "test_and_valid = adf.drop(train.index)\n",
    "test = test_and_valid.sample(frac=0.90,random_state=420) \n",
    "# valid = test_and_valid.drop(test.index)\n",
    "\n",
    "train_loader = DataLoader(audioDataset(train,SR), batch_size=128,shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(audioDataset(test,SR), batch_size=256,shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5623, 266)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Spec_DVD(nn.Module):\n",
    "    def __init__(self,embed_only=False,dropout=0.075):\n",
    "        super(Conv_Spec_DVD, self).__init__()\n",
    "        self.embed_only = embed_only\n",
    "        self.dropout = dropout\n",
    "        self.conv_1d = nn.Sequential(\n",
    "                nn.Conv1d(1,128,500, stride=2, padding=5),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(128, 128, 250, stride=2, padding=4),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(128, 256, 100, stride=2, padding=3),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(256, 256, 100, stride=2, padding=2),\n",
    "                nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(256, 128, 80, stride=1, padding=3),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(128, 128, 40, stride=1, padding=3),\n",
    "                nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU())\n",
    "        self.spectrogram_layer = nn.Sequential(\n",
    "                nn.Linear(30*9,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.Linear(64,32),\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.Linear(32,16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16,16),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dropout),\n",
    "                )\n",
    "        self.l2 = nn.Sequential(\n",
    "                nn.Linear(128,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.Linear(64,32),\n",
    "                nn.Dropout(self.dropout),\n",
    "                nn.Linear(32,16),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dropout),\n",
    "                )\n",
    "        self.l3 = nn.Sequential(\n",
    "                  nn.Linear(16+16,32),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Dropout(self.dropout),\n",
    "                  nn.Linear(32,16),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(16,4),\n",
    "                )\n",
    "\n",
    "    def forward(self, x_sig,x_spec):\n",
    "        x_sig = x_sig.float()\n",
    "        bs = x_sig.shape[0]\n",
    "        bs_spec = x_spec.shape[0]\n",
    "        x_sig = x_sig.reshape(bs,1,-1).to(device)\n",
    "        x1_1d = self.conv_1d(x_sig)\n",
    "        flat_spec = x_spec.reshape([bs_spec,-1])\n",
    "        x1_fc = self.spectrogram_layer(flat_spec)\n",
    "        x1_1d = x1_1d.reshape(bs,-1)\n",
    "        x2 = self.l2(x1_1d)\n",
    "        x_agg = torch.cat((x2,x1_fc),dim=1)\n",
    "        x_final = self.l3(x_agg)\n",
    "        return x_final\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "try:\n",
    "    del cnet\n",
    "except:\n",
    "    pass\n",
    "cnet = Conv_Spec_DVD(embed_only=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(\"models/1d_conv/0.025_0.0013_ensemble.checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(np.log(len(ecg_paths)/np.sum(ecg_paths).to_numpy()))).to(device)\n",
    "loss_func = nn.CrossEntropyLoss(weight = w.float() )\n",
    "lr = 0.001 # learning rate\n",
    "optimizer = torch.optim.Adam(cnet.parameters(), lr=lr)\n",
    "smallest_loss,smallest_vloss = 1,1\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0] val loss: 2.72806, loss: 1.39423\n",
      "[1, 5] val loss: 2.75109, loss: 1.36761\n",
      "[1, 10] val loss: 2.82184, loss: 1.36740\n",
      "[1, 15] val loss: 2.72161, loss: 1.31945\n",
      "[1, 20] val loss: 2.58296, loss: 1.30759\n",
      "[1, 25] val loss: 2.27425, loss: 1.07510\n",
      "[1, 30] val loss: 2.65677, loss: 1.23716\n",
      "[1, 35] val loss: 3.17491, loss: 1.16806\n",
      "[1, 40] val loss: 2.50277, loss: 1.21869\n",
      "[2, 0] val loss: 2.68541, loss: 0.92385\n",
      "[2, 5] val loss: 2.60521, loss: 1.04283\n",
      "[2, 10] val loss: 2.96875, loss: 1.12549\n",
      "[2, 15] val loss: 2.69739, loss: 1.12885\n",
      "[2, 20] val loss: 2.02819, loss: 0.91560\n",
      "[2, 25] val loss: 1.98080, loss: 1.05156\n",
      "[2, 30] val loss: 3.32245, loss: 0.99440\n",
      "[2, 35] val loss: 2.53218, loss: 1.07143\n",
      "[2, 40] val loss: 1.85834, loss: 1.04240\n",
      "[3, 0] val loss: 3.15444, loss: 0.72607\n",
      "[3, 5] val loss: 2.36602, loss: 0.65821\n",
      "[3, 10] val loss: 1.85080, loss: 0.90044\n",
      "[3, 15] val loss: 4.87488, loss: 0.72472\n",
      "[3, 20] val loss: 2.01938, loss: 0.79594\n",
      "[3, 25] val loss: 1.95274, loss: 0.82339\n",
      "[3, 30] val loss: 2.29721, loss: 0.83963\n",
      "[3, 35] val loss: 1.92462, loss: 0.88808\n",
      "[3, 40] val loss: 1.50061, loss: 0.78277\n",
      "[4, 0] val loss: 1.74718, loss: 0.72060\n",
      "[4, 5] val loss: 2.30085, loss: 0.70207\n",
      "[4, 10] val loss: 1.75781, loss: 0.70293\n",
      "[4, 15] val loss: 1.51323, loss: 0.61109\n",
      "[4, 20] val loss: 1.26029, loss: 0.86074\n",
      "[4, 25] val loss: 3.13542, loss: 0.65134\n",
      "[4, 30] val loss: 1.20380, loss: 0.80184\n",
      "[4, 35] val loss: 1.90179, loss: 0.66212\n",
      "[4, 40] val loss: 1.41984, loss: 0.65505\n",
      "[5, 0] val loss: 1.37876, loss: 0.77594\n",
      "[5, 5] val loss: 1.41881, loss: 0.56590\n",
      "[5, 10] val loss: 1.48386, loss: 0.58362\n",
      "[5, 15] val loss: 1.40054, loss: 0.74257\n",
      "[5, 20] val loss: 1.91783, loss: 0.74339\n",
      "[5, 25] val loss: 1.12748, loss: 0.62263\n",
      "[5, 30] val loss: 1.42462, loss: 0.67643\n",
      "[5, 35] val loss: 1.30544, loss: 0.62660\n",
      "[5, 40] val loss: 1.58080, loss: 0.98680\n",
      "[6, 0] val loss: 1.29649, loss: 0.71379\n",
      "[6, 5] val loss: 1.35396, loss: 0.64558\n",
      "[6, 10] val loss: 1.44786, loss: 0.60002\n",
      "[6, 15] val loss: 1.30355, loss: 0.58153\n",
      "[6, 20] val loss: 1.60786, loss: 0.72716\n",
      "[6, 25] val loss: 0.93469, loss: 0.74017\n",
      "[6, 30] val loss: 1.47387, loss: 0.60004\n",
      "[6, 35] val loss: 1.28192, loss: 0.68287\n",
      "[6, 40] val loss: 1.74262, loss: 0.54336\n",
      "[7, 0] val loss: 1.20356, loss: 0.47671\n",
      "[7, 5] val loss: 1.33727, loss: 0.57851\n",
      "[7, 10] val loss: 1.47031, loss: 0.49897\n",
      "[7, 15] val loss: 1.31252, loss: 0.72687\n",
      "[7, 20] val loss: 1.17577, loss: 0.51665\n",
      "[7, 25] val loss: 1.13415, loss: 0.67889\n",
      "[7, 30] val loss: 1.14710, loss: 0.66088\n",
      "[7, 35] val loss: 1.29637, loss: 0.69216\n",
      "[7, 40] val loss: 1.87271, loss: 0.66718\n",
      "[8, 0] val loss: 0.97936, loss: 0.61844\n",
      "[8, 5] val loss: 2.22454, loss: 0.64344\n",
      "[8, 10] val loss: 1.26252, loss: 0.66413\n",
      "[8, 15] val loss: 1.21125, loss: 0.60195\n",
      "[8, 20] val loss: 1.19005, loss: 0.62349\n",
      "[8, 25] val loss: 1.25149, loss: 0.46392\n",
      "[8, 30] val loss: 1.27183, loss: 0.59054\n",
      "[8, 35] val loss: 1.28870, loss: 0.54132\n",
      "[8, 40] val loss: 1.55913, loss: 0.48776\n",
      "[9, 0] val loss: 1.75131, loss: 0.49993\n",
      "[9, 5] val loss: 3.05417, loss: 0.56583\n",
      "[9, 10] val loss: 1.12014, loss: 0.53526\n",
      "[9, 15] val loss: 2.28628, loss: 0.54238\n",
      "[9, 20] val loss: 1.61103, loss: 0.56464\n",
      "[9, 25] val loss: 0.93608, loss: 0.50047\n",
      "[9, 30] val loss: 1.53414, loss: 0.55171\n",
      "[9, 35] val loss: 1.26875, loss: 0.74725\n",
      "[9, 40] val loss: 1.29808, loss: 0.73398\n",
      "[10, 0] val loss: 1.74915, loss: 0.48312\n",
      "[10, 5] val loss: 1.28302, loss: 0.56174\n",
      "[10, 10] val loss: 1.29030, loss: 0.47254\n",
      "[10, 15] val loss: 1.35218, loss: 0.51686\n",
      "[10, 20] val loss: 1.51782, loss: 0.55062\n",
      "[10, 25] val loss: 1.13814, loss: 0.50946\n",
      "[10, 30] val loss: 1.39065, loss: 0.53331\n",
      "[10, 35] val loss: 1.31479, loss: 0.53213\n",
      "[10, 40] val loss: 1.30884, loss: 0.48013\n",
      "[11, 0] val loss: 1.06441, loss: 0.70466\n",
      "[11, 5] val loss: 0.99706, loss: 0.49904\n",
      "[11, 10] val loss: 1.47576, loss: 0.57593\n",
      "[11, 15] val loss: 1.92911, loss: 0.59921\n",
      "[11, 20] val loss: 0.84192, loss: 0.50824\n",
      "[11, 25] val loss: 1.24187, loss: 0.46654\n",
      "[11, 30] val loss: 1.09421, loss: 0.44823\n",
      "[11, 35] val loss: 0.96203, loss: 0.53454\n",
      "[11, 40] val loss: 2.37894, loss: 0.44951\n",
      "[12, 0] val loss: 1.02419, loss: 0.57046\n",
      "[12, 5] val loss: 0.83236, loss: 0.61109\n",
      "[12, 10] val loss: 1.09730, loss: 0.48201\n",
      "[12, 15] val loss: 1.17490, loss: 0.50275\n",
      "[12, 20] val loss: 1.44262, loss: 0.67596\n",
      "[12, 25] val loss: 1.16037, loss: 0.50842\n",
      "[12, 30] val loss: 0.95398, loss: 0.50354\n",
      "[12, 35] val loss: 1.18277, loss: 0.41054\n",
      "[12, 40] val loss: 1.27809, loss: 0.40853\n",
      "[13, 0] val loss: 1.21770, loss: 0.81438\n",
      "[13, 5] val loss: 1.18392, loss: 0.46009\n",
      "[13, 10] val loss: 1.00482, loss: 0.52796\n",
      "[13, 15] val loss: 0.90846, loss: 0.53311\n",
      "[13, 20] val loss: 1.01848, loss: 0.66402\n",
      "[13, 25] val loss: 1.10906, loss: 0.36643\n",
      "[13, 30] val loss: 0.75091, loss: 0.50514\n",
      "[13, 35] val loss: 1.35422, loss: 0.38594\n",
      "[13, 40] val loss: 1.32348, loss: 0.50811\n",
      "[14, 0] val loss: 1.05684, loss: 0.53392\n",
      "[14, 5] val loss: 1.16685, loss: 0.39898\n",
      "[14, 10] val loss: 1.55066, loss: 0.46587\n",
      "[14, 15] val loss: 1.94175, loss: 0.45973\n",
      "[14, 20] val loss: 1.16388, loss: 0.51090\n",
      "[14, 25] val loss: 0.80366, loss: 0.50023\n",
      "[14, 30] val loss: 1.78765, loss: 0.44976\n",
      "[14, 35] val loss: 1.84100, loss: 0.48051\n",
      "[14, 40] val loss: 1.09201, loss: 0.43719\n",
      "[15, 0] val loss: 1.31160, loss: 0.46541\n",
      "[15, 5] val loss: 0.77846, loss: 0.60459\n",
      "[15, 10] val loss: 1.01250, loss: 0.34859\n",
      "[15, 15] val loss: 1.67967, loss: 0.46603\n",
      "[15, 20] val loss: 1.08535, loss: 0.39304\n",
      "[15, 25] val loss: 2.61455, loss: 0.48016\n",
      "[15, 30] val loss: 0.81729, loss: 0.39035\n",
      "[15, 35] val loss: 1.69706, loss: 0.41548\n",
      "[15, 40] val loss: 1.62276, loss: 0.40507\n",
      "[16, 0] val loss: 0.95262, loss: 0.35304\n",
      "[16, 5] val loss: 0.90608, loss: 0.43829\n",
      "[16, 10] val loss: 1.29082, loss: 0.45290\n",
      "[16, 15] val loss: 1.35974, loss: 0.43743\n",
      "[16, 20] val loss: 1.25523, loss: 0.43566\n",
      "[16, 25] val loss: 1.12431, loss: 0.37482\n",
      "[16, 30] val loss: 1.03808, loss: 0.43684\n",
      "[16, 35] val loss: 1.11711, loss: 0.58409\n",
      "[16, 40] val loss: 0.75275, loss: 0.34649\n",
      "[17, 0] val loss: 0.82529, loss: 0.42444\n",
      "[17, 5] val loss: 2.80640, loss: 0.36926\n",
      "[17, 10] val loss: 0.96093, loss: 0.33994\n",
      "[17, 15] val loss: 1.53577, loss: 0.40226\n",
      "[17, 20] val loss: 0.76119, loss: 0.42704\n"
     ]
    }
   ],
   "source": [
    "SCALE_FACTOR = 0.5\n",
    "num_windows = 5\n",
    "window_shift = 300\n",
    "smallest_loss,smallest_vloss = 1000,1000\n",
    "step = 0\n",
    "for epoch in range(40): \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        train_loss = 0\n",
    "        bs = len(data[\"signal\"]) # batch size\n",
    "        signal = interpolate(data[\"signal\"].reshape([bs,1,-1]),scale_factor = SCALE_FACTOR,recompute_scale_factor=False).reshape([bs,1,-1])\n",
    "        spectrums = torch.stack(list(map(spec_tf,data[\"signal\"].float())),0).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnet(signal,spectrums)\n",
    "        y = torch.tensor(le_major.transform(data[\"minor\"])).to(device)\n",
    "        loss = loss_func(outputs,y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if i%5==0:\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0\n",
    "                for iv,datav in enumerate(test_loader, 0):\n",
    "                    signalv = interpolate(datav[\"signal\"].reshape([len(datav[\"signal\"]),1,-1]),scale_factor = SCALE_FACTOR,recompute_scale_factor=False).reshape([len(datav[\"signal\"]),-1])\n",
    "                    spectrumsv = torch.stack(list(map(spec_tf,datav[\"signal\"].float())),0).to(device)\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    voutputs = cnet(signalv,spectrumsv )\n",
    "                    vy = torch.tensor(le_major.transform(datav[\"minor\"])).to(device)\n",
    "                    vloss = loss_func(voutputs,vy.long())\n",
    "                    val_loss += vloss\n",
    "            print('[%d, %d] val loss: %.5f, loss: %.5f'%(epoch + 1, i , val_loss,train_loss))\n",
    "    #         writer.add_scalar('Loss/Training', train_loss,)\n",
    "    #         writer.add_scalar('Loss/Validation', val_loss)\n",
    "            if val_loss < smallest_vloss:        \n",
    "                torch.save({\n",
    "                'epoch': epoch,\n",
    "                'vloss': vloss,\n",
    "                'model_state_dict': cnet.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, \"models/1d_conv_dvd/%.3f_%.4f_.checkpoint\"%(val_loss,train_loss,))\n",
    "                smallest_vloss = val_loss\n",
    "                smallest_loss = train_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
